# Spatial‑Risk‑TDA

*A Topological Data Analysis (TDA) workflow for measuring un‑measured spatial risk and fitting Besag–York–Mollié (BYM‑T) models to opioid‑related health outcomes.*

This repository contains the full research pipeline—from raw county‑level data to Bayesian spatial models—used in our study of opioid vulnerability across U.S. counties. The core stages are:

1. **Data pre‑processing** – Clean Social Vulnerability Index (SVI) shapefiles, overdose mortality counts, and census populations.
2. **TDA summary generation** – Build adjacency‑based simplicial complexes and extract persistence summaries that capture latent spatial structure.
3. **Bayesian modeling** – Re‑parameterise the BYM model to include the TDA effect (BYM‑T) and fit it in selected states.

---

## 📁 Repository layout

```text
SPATIAL-RISK-TDA/
├── data/
│   ├── raw_data/                # 🔒 original SVI & overdose data (not tracked)
│   └── processed_data/          # 📈 cleaned & merged data ready for analysis
│
├── data_processing/
│   ├── main_data_process.ipynb  # end‑to‑end notebook: raw → processed
│   ├── svi_treat_null.py        # helper script to impute / treat SVI nulls
│   ├── smr.py                   # utilities for Standard Mortality Ratio (SMR)
│   └── __pycache__/             # auto‑generated bytecode
│
├── simulations/                 # synthetic experiments
│   ├── controlled_ac.ipynb      # vary autocorrelation strength
│   ├── controlled_avg.ipynb     # vary mean risk level
│   └── controlled_grid.ipynb    # vary spatial grid patterns
│
├── results/                     # model outputs, figures & tables
│
├── utills/                      # general utility modules (I/O, viz, etc.)
│
├── generate_tda_summaries.ipynb # compute persistence diagrams & images
├── bym_modeling_tn.ipynb        # BYM‑T case study – Tennessee
├── bym_modeling_va.ipynb        # BYM‑T case study – Virginia
│
├── requirements.txt             # reproducible Python environment
├── .gitignore                   # ignore large / sensitive files
└── README.md                    # you are here
```

> **Note**: Raw data live in `data/raw_data/` and are *not* under version control. Add them manually following the instructions below.

---

## 🚀 Quick‑start

### 1. Clone & create environment

```bash
git clone https://github.com/<your‑org>/spatial-risk-tda.git
cd spatial-risk-tda
conda create -n spatial-tda python=3.11
conda activate spatial-tda
pip install -r requirements.txt
```

### 2. Supply raw inputs

Place the following files in **`data/raw_data/`**:

| Dataset                                    | Source | Example filename          |
| ------------------------------------------ | ------ | ------------------------- |
| CDC WONDER overdose mortality counts       | CDC    | `overdose_2014_2020.csv`  |
| Social Vulnerability Index (SVI) shapefile | ATSDR  | `SVI_2018_US.shp`         |
| ACS county‑level population estimates      | Census | `acs_2019_population.csv` |

### 3. Run the pre‑processing pipeline

Open **`data_processing/main_data_process.ipynb`** and execute all cells.

Alternatively, run the key scripts directly:

```bash
python data_processing/svi_treat_null.py   # clean & impute SVI
python data_processing/smr.py              # calculate county‑level SMR
```

Cleaned outputs will be written to **`data/processed_data/`**.

### 4. Generate TDA summaries

```bash
jupyter nbconvert --execute generate_tda_summaries.ipynb
```

This notebook constructs adjacency‑based simplicial complexes for each county‑level snapshot and stores persistence diagrams / images needed for downstream modeling.

### 5. Fit BYM‑T models

Select a state‑specific notebook (e.g. **`bym_modeling_tn.ipynb`**) and run the full workflow to:

1. Load processed data and TDA summaries.
2. Compose the BYM‑T hierarchical model in PyMC.
3. Sample with NUTS, diagnose convergence, and save posterior draws.
4. Produce comparative WAIC/LOO metrics and visualise relative risk maps.

Outputs (trace files, figures) are saved under **`results/`**.

### 6. (Optional) Synthetic simulations

Use notebooks in **`simulations/`** to evaluate how well TDA summaries capture known spatial structures under controlled settings.

---

## 🔄 Reproducibility tips

* `requirements.txt` pins all critical dependencies; consider `pip install -r requirements.txt --no-binary :all:` for deterministic builds.
* Set the `PYTHONHASHSEED` environment variable for exact hash‑based splits.
* For GPU sampling (CUDA‑enabled PyMC), ensure a compatible NVIDIA driver and CUDA runtime are present.

---

## 📜 Citation

If you use this code, please cite:

<!-- ```bibtex
@article{your2025tda,
  title   = {},
  author  = {},
  journal = {},
  year    = {}
}
``` -->

---

## 📝 License

MIT – see `LICENSE` for details.

---

*Happy modeling!*
